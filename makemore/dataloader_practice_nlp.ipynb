{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Natural Language Processing\n",
    "We will analyze the text of the book war and piece and try to generate new text in the same style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "np.random.seed(42)\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D://Datasets/names.txt\", 'r') as file:\n",
    "    names = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 0,\n",
       " 'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = sorted(list(set(''.join(names))))\n",
    "chartoidx = {}\n",
    "idxtochar = {}\n",
    "chartoidx['.'] = 0   # Putting a special token to denote the start and the end of a sentence.\n",
    "idxtochar[0] = '.'\n",
    "for i,char in enumerate(vocabulary):\n",
    "    chartoidx[char] = i+1\n",
    "    idxtochar[i+1] = char\n",
    "\n",
    "chartoidx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A bigram model gives us two samples occuring next to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('e', 'm'), ('m', 'm'), ('m', 'a')]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(names[0], names[0][1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to generate bigrams is to count the number of times bigrams occur in the model and sample according to the probability distribution of the bigram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('n', '.'), 6763),\n",
       " (('a', '.'), 6640),\n",
       " (('a', 'n'), 5438),\n",
       " (('.', 'a'), 4410),\n",
       " (('e', '.'), 3983),\n",
       " (('a', 'r'), 3264),\n",
       " (('e', 'l'), 3248),\n",
       " (('r', 'i'), 3033),\n",
       " (('n', 'a'), 2977),\n",
       " (('.', 'k'), 2963),\n",
       " (('l', 'e'), 2921),\n",
       " (('e', 'n'), 2675),\n",
       " (('l', 'a'), 2623),\n",
       " (('m', 'a'), 2590),\n",
       " (('.', 'm'), 2538),\n",
       " (('a', 'l'), 2528),\n",
       " (('i', '.'), 2489),\n",
       " (('l', 'i'), 2480),\n",
       " (('i', 'a'), 2445),\n",
       " (('.', 'j'), 2422),\n",
       " (('o', 'n'), 2411),\n",
       " (('h', '.'), 2409),\n",
       " (('r', 'a'), 2356),\n",
       " (('a', 'h'), 2332),\n",
       " (('h', 'a'), 2244),\n",
       " (('y', 'a'), 2143),\n",
       " (('i', 'n'), 2126),\n",
       " (('.', 's'), 2055),\n",
       " (('a', 'y'), 2050),\n",
       " (('y', '.'), 2007),\n",
       " (('e', 'r'), 1958),\n",
       " (('n', 'n'), 1906),\n",
       " (('y', 'n'), 1826),\n",
       " (('k', 'a'), 1731),\n",
       " (('n', 'i'), 1725),\n",
       " (('r', 'e'), 1697),\n",
       " (('.', 'd'), 1690),\n",
       " (('i', 'e'), 1653),\n",
       " (('a', 'i'), 1650),\n",
       " (('.', 'r'), 1639),\n",
       " (('a', 'm'), 1634),\n",
       " (('l', 'y'), 1588),\n",
       " (('.', 'l'), 1572),\n",
       " (('.', 'c'), 1542),\n",
       " (('.', 'e'), 1531),\n",
       " (('j', 'a'), 1473),\n",
       " (('r', '.'), 1377),\n",
       " (('n', 'e'), 1359),\n",
       " (('l', 'l'), 1345),\n",
       " (('i', 'l'), 1345),\n",
       " (('i', 's'), 1316),\n",
       " (('l', '.'), 1314),\n",
       " (('.', 't'), 1308),\n",
       " (('.', 'b'), 1306),\n",
       " (('d', 'a'), 1303),\n",
       " (('s', 'h'), 1285),\n",
       " (('d', 'e'), 1283),\n",
       " (('e', 'e'), 1271),\n",
       " (('m', 'i'), 1256),\n",
       " (('s', 'a'), 1201),\n",
       " (('s', '.'), 1169),\n",
       " (('.', 'n'), 1146),\n",
       " (('a', 's'), 1118),\n",
       " (('y', 'l'), 1104),\n",
       " (('e', 'y'), 1070),\n",
       " (('o', 'r'), 1059),\n",
       " (('a', 'd'), 1042),\n",
       " (('t', 'a'), 1027),\n",
       " (('.', 'z'), 929),\n",
       " (('v', 'i'), 911),\n",
       " (('k', 'e'), 895),\n",
       " (('s', 'e'), 884),\n",
       " (('.', 'h'), 874),\n",
       " (('r', 'o'), 869),\n",
       " (('e', 's'), 861),\n",
       " (('z', 'a'), 860),\n",
       " (('o', '.'), 855),\n",
       " (('i', 'r'), 849),\n",
       " (('b', 'r'), 842),\n",
       " (('a', 'v'), 834),\n",
       " (('m', 'e'), 818),\n",
       " (('e', 'i'), 818),\n",
       " (('c', 'a'), 815),\n",
       " (('i', 'y'), 779),\n",
       " (('r', 'y'), 773),\n",
       " (('e', 'm'), 769),\n",
       " (('s', 't'), 765),\n",
       " (('h', 'i'), 729),\n",
       " (('t', 'e'), 716),\n",
       " (('n', 'd'), 704),\n",
       " (('l', 'o'), 692),\n",
       " (('a', 'e'), 692),\n",
       " (('a', 't'), 687),\n",
       " (('s', 'i'), 684),\n",
       " (('e', 'a'), 679),\n",
       " (('d', 'i'), 674),\n",
       " (('h', 'e'), 674),\n",
       " (('.', 'g'), 669),\n",
       " (('t', 'o'), 667),\n",
       " (('c', 'h'), 664),\n",
       " (('b', 'e'), 655),\n",
       " (('t', 'h'), 647),\n",
       " (('v', 'a'), 642),\n",
       " (('o', 'l'), 619),\n",
       " (('.', 'i'), 591),\n",
       " (('i', 'o'), 588),\n",
       " (('e', 't'), 580),\n",
       " (('v', 'e'), 568),\n",
       " (('a', 'k'), 568),\n",
       " (('a', 'a'), 556),\n",
       " (('c', 'e'), 551),\n",
       " (('a', 'b'), 541),\n",
       " (('i', 't'), 541),\n",
       " (('.', 'y'), 535),\n",
       " (('t', 'i'), 532),\n",
       " (('s', 'o'), 531),\n",
       " (('m', '.'), 516),\n",
       " (('d', '.'), 516),\n",
       " (('.', 'p'), 515),\n",
       " (('i', 'c'), 509),\n",
       " (('k', 'i'), 509),\n",
       " (('o', 's'), 504),\n",
       " (('n', 'o'), 496),\n",
       " (('t', '.'), 483),\n",
       " (('j', 'o'), 479),\n",
       " (('u', 's'), 474),\n",
       " (('a', 'c'), 470),\n",
       " (('n', 'y'), 465),\n",
       " (('e', 'v'), 463),\n",
       " (('s', 's'), 461),\n",
       " (('m', 'o'), 452),\n",
       " (('i', 'k'), 445),\n",
       " (('n', 't'), 443),\n",
       " (('i', 'd'), 440),\n",
       " (('j', 'e'), 440),\n",
       " (('a', 'z'), 435),\n",
       " (('i', 'g'), 428),\n",
       " (('i', 'm'), 427),\n",
       " (('r', 'r'), 425),\n",
       " (('d', 'r'), 424),\n",
       " (('.', 'f'), 417),\n",
       " (('u', 'r'), 414),\n",
       " (('r', 'l'), 413),\n",
       " (('y', 's'), 401),\n",
       " (('.', 'o'), 394),\n",
       " (('e', 'd'), 384),\n",
       " (('a', 'u'), 381),\n",
       " (('c', 'o'), 380),\n",
       " (('k', 'y'), 379),\n",
       " (('d', 'o'), 378),\n",
       " (('.', 'v'), 376),\n",
       " (('t', 't'), 374),\n",
       " (('z', 'e'), 373),\n",
       " (('z', 'i'), 364),\n",
       " (('k', '.'), 363),\n",
       " (('g', 'h'), 360),\n",
       " (('t', 'r'), 352),\n",
       " (('k', 'o'), 344),\n",
       " (('t', 'y'), 341),\n",
       " (('g', 'e'), 334),\n",
       " (('g', 'a'), 330),\n",
       " (('l', 'u'), 324),\n",
       " (('b', 'a'), 321),\n",
       " (('d', 'y'), 317),\n",
       " (('c', 'k'), 316),\n",
       " (('.', 'w'), 307),\n",
       " (('k', 'h'), 307),\n",
       " (('u', 'l'), 301),\n",
       " (('y', 'e'), 301),\n",
       " (('y', 'r'), 291),\n",
       " (('m', 'y'), 287),\n",
       " (('h', 'o'), 287),\n",
       " (('w', 'a'), 280),\n",
       " (('s', 'l'), 279),\n",
       " (('n', 's'), 278),\n",
       " (('i', 'z'), 277),\n",
       " (('u', 'n'), 275),\n",
       " (('o', 'u'), 275),\n",
       " (('n', 'g'), 273),\n",
       " (('y', 'd'), 272),\n",
       " (('c', 'i'), 271),\n",
       " (('y', 'o'), 271),\n",
       " (('i', 'v'), 269),\n",
       " (('e', 'o'), 269),\n",
       " (('o', 'm'), 261),\n",
       " (('r', 'u'), 252),\n",
       " (('f', 'a'), 242),\n",
       " (('b', 'i'), 217),\n",
       " (('s', 'y'), 215),\n",
       " (('n', 'c'), 213),\n",
       " (('h', 'y'), 213),\n",
       " (('p', 'a'), 209),\n",
       " (('r', 't'), 208),\n",
       " (('q', 'u'), 206),\n",
       " (('p', 'h'), 204),\n",
       " (('h', 'r'), 204),\n",
       " (('j', 'u'), 202),\n",
       " (('g', 'r'), 201),\n",
       " (('p', 'e'), 197),\n",
       " (('n', 'l'), 195),\n",
       " (('y', 'i'), 192),\n",
       " (('g', 'i'), 190),\n",
       " (('o', 'd'), 190),\n",
       " (('r', 's'), 190),\n",
       " (('r', 'd'), 187),\n",
       " (('h', 'l'), 185),\n",
       " (('s', 'u'), 185),\n",
       " (('a', 'x'), 182),\n",
       " (('e', 'z'), 181),\n",
       " (('e', 'k'), 178),\n",
       " (('o', 'v'), 176),\n",
       " (('a', 'j'), 175),\n",
       " (('o', 'h'), 171),\n",
       " (('u', 'e'), 169),\n",
       " (('m', 'm'), 168),\n",
       " (('a', 'g'), 168),\n",
       " (('h', 'u'), 166),\n",
       " (('x', '.'), 164),\n",
       " (('u', 'a'), 163),\n",
       " (('r', 'm'), 162),\n",
       " (('a', 'w'), 161),\n",
       " (('f', 'i'), 160),\n",
       " (('z', '.'), 160),\n",
       " (('u', '.'), 155),\n",
       " (('u', 'm'), 154),\n",
       " (('e', 'c'), 153),\n",
       " (('v', 'o'), 153),\n",
       " (('e', 'h'), 152),\n",
       " (('p', 'r'), 151),\n",
       " (('d', 'd'), 149),\n",
       " (('o', 'a'), 149),\n",
       " (('w', 'e'), 149),\n",
       " (('w', 'i'), 148),\n",
       " (('y', 'm'), 148),\n",
       " (('z', 'y'), 147),\n",
       " (('n', 'z'), 145),\n",
       " (('y', 'u'), 141),\n",
       " (('r', 'n'), 140),\n",
       " (('o', 'b'), 140),\n",
       " (('k', 'l'), 139),\n",
       " (('m', 'u'), 139),\n",
       " (('l', 'd'), 138),\n",
       " (('h', 'n'), 138),\n",
       " (('u', 'd'), 136),\n",
       " (('.', 'x'), 134),\n",
       " (('t', 'l'), 134),\n",
       " (('a', 'f'), 134),\n",
       " (('o', 'e'), 132),\n",
       " (('e', 'x'), 132),\n",
       " (('e', 'g'), 125),\n",
       " (('f', 'e'), 123),\n",
       " (('z', 'l'), 123),\n",
       " (('u', 'i'), 121),\n",
       " (('v', 'y'), 121),\n",
       " (('e', 'b'), 121),\n",
       " (('r', 'h'), 121),\n",
       " (('j', 'i'), 119),\n",
       " (('o', 't'), 118),\n",
       " (('d', 'h'), 118),\n",
       " (('h', 'm'), 117),\n",
       " (('c', 'l'), 116),\n",
       " (('o', 'o'), 115),\n",
       " (('y', 'c'), 115),\n",
       " (('o', 'w'), 114),\n",
       " (('o', 'c'), 114),\n",
       " (('f', 'r'), 114),\n",
       " (('b', '.'), 114),\n",
       " (('m', 'b'), 112),\n",
       " (('z', 'o'), 110),\n",
       " (('i', 'b'), 110),\n",
       " (('i', 'u'), 109),\n",
       " (('k', 'r'), 109),\n",
       " (('g', '.'), 108),\n",
       " (('y', 'v'), 106),\n",
       " (('t', 'z'), 105),\n",
       " (('b', 'o'), 105),\n",
       " (('c', 'y'), 104),\n",
       " (('y', 't'), 104),\n",
       " (('u', 'b'), 103),\n",
       " (('u', 'c'), 103),\n",
       " (('x', 'a'), 103),\n",
       " (('b', 'l'), 103),\n",
       " (('o', 'y'), 103),\n",
       " (('x', 'i'), 102),\n",
       " (('i', 'f'), 101),\n",
       " (('r', 'c'), 99),\n",
       " (('c', '.'), 97),\n",
       " (('m', 'r'), 97),\n",
       " (('n', 'u'), 96),\n",
       " (('o', 'p'), 95),\n",
       " (('i', 'h'), 95),\n",
       " (('k', 's'), 95),\n",
       " (('l', 's'), 94),\n",
       " (('u', 'k'), 93),\n",
       " (('.', 'q'), 92),\n",
       " (('d', 'u'), 92),\n",
       " (('s', 'm'), 90),\n",
       " (('r', 'k'), 90),\n",
       " (('i', 'x'), 89),\n",
       " (('v', '.'), 88),\n",
       " (('y', 'k'), 86),\n",
       " (('u', 'w'), 86),\n",
       " (('g', 'u'), 85),\n",
       " (('b', 'y'), 83),\n",
       " (('e', 'p'), 83),\n",
       " (('g', 'o'), 83),\n",
       " (('s', 'k'), 82),\n",
       " (('u', 't'), 82),\n",
       " (('a', 'p'), 82),\n",
       " (('e', 'f'), 82),\n",
       " (('i', 'i'), 82),\n",
       " (('r', 'v'), 80),\n",
       " (('f', '.'), 80),\n",
       " (('t', 'u'), 78),\n",
       " (('y', 'z'), 78),\n",
       " (('.', 'u'), 78),\n",
       " (('l', 't'), 77),\n",
       " (('r', 'g'), 76),\n",
       " (('c', 'r'), 76),\n",
       " (('i', 'j'), 76),\n",
       " (('w', 'y'), 73),\n",
       " (('z', 'u'), 73),\n",
       " (('l', 'v'), 72),\n",
       " (('h', 't'), 71),\n",
       " (('j', '.'), 71),\n",
       " (('x', 't'), 70),\n",
       " (('o', 'i'), 69),\n",
       " (('e', 'u'), 69),\n",
       " (('o', 'k'), 68),\n",
       " (('b', 'd'), 65),\n",
       " (('a', 'o'), 63),\n",
       " (('p', 'i'), 61),\n",
       " (('s', 'c'), 60),\n",
       " (('d', 'l'), 60),\n",
       " (('l', 'm'), 60),\n",
       " (('a', 'q'), 60),\n",
       " (('f', 'o'), 60),\n",
       " (('p', 'o'), 59),\n",
       " (('n', 'k'), 58),\n",
       " (('w', 'n'), 58),\n",
       " (('u', 'h'), 58),\n",
       " (('e', 'j'), 55),\n",
       " (('n', 'v'), 55),\n",
       " (('s', 'r'), 55),\n",
       " (('o', 'z'), 54),\n",
       " (('i', 'p'), 53),\n",
       " (('l', 'b'), 52),\n",
       " (('i', 'q'), 52),\n",
       " (('w', '.'), 51),\n",
       " (('m', 'c'), 51),\n",
       " (('s', 'p'), 51),\n",
       " (('e', 'w'), 50),\n",
       " (('k', 'u'), 50),\n",
       " (('v', 'r'), 48),\n",
       " (('u', 'g'), 47),\n",
       " (('o', 'x'), 45),\n",
       " (('u', 'z'), 45),\n",
       " (('z', 'z'), 45),\n",
       " (('j', 'h'), 45),\n",
       " (('b', 'u'), 45),\n",
       " (('o', 'g'), 44),\n",
       " (('n', 'r'), 44),\n",
       " (('f', 'f'), 44),\n",
       " (('n', 'j'), 44),\n",
       " (('z', 'h'), 43),\n",
       " (('c', 'c'), 42),\n",
       " (('r', 'b'), 41),\n",
       " (('x', 'o'), 41),\n",
       " (('b', 'h'), 41),\n",
       " (('p', 'p'), 39),\n",
       " (('x', 'l'), 39),\n",
       " (('h', 'v'), 39),\n",
       " (('b', 'b'), 38),\n",
       " (('m', 'p'), 38),\n",
       " (('x', 'x'), 38),\n",
       " (('u', 'v'), 37),\n",
       " (('x', 'e'), 36),\n",
       " (('w', 'o'), 36),\n",
       " (('c', 't'), 35),\n",
       " (('z', 'm'), 35),\n",
       " (('t', 's'), 35),\n",
       " (('m', 's'), 35),\n",
       " (('c', 'u'), 35),\n",
       " (('o', 'f'), 34),\n",
       " (('u', 'x'), 34),\n",
       " (('k', 'w'), 34),\n",
       " (('p', '.'), 33),\n",
       " (('g', 'l'), 32),\n",
       " (('z', 'r'), 32),\n",
       " (('d', 'n'), 31),\n",
       " (('g', 't'), 31),\n",
       " (('g', 'y'), 31),\n",
       " (('h', 's'), 31),\n",
       " (('x', 's'), 31),\n",
       " (('g', 's'), 30),\n",
       " (('x', 'y'), 30),\n",
       " (('y', 'g'), 30),\n",
       " (('d', 'm'), 30),\n",
       " (('d', 's'), 29),\n",
       " (('h', 'k'), 29),\n",
       " (('y', 'x'), 28),\n",
       " (('q', '.'), 28),\n",
       " (('g', 'n'), 27),\n",
       " (('y', 'b'), 27),\n",
       " (('g', 'w'), 26),\n",
       " (('n', 'h'), 26),\n",
       " (('k', 'n'), 26),\n",
       " (('g', 'g'), 25),\n",
       " (('d', 'g'), 25),\n",
       " (('l', 'c'), 25),\n",
       " (('r', 'j'), 25),\n",
       " (('w', 'u'), 25),\n",
       " (('l', 'k'), 24),\n",
       " (('m', 'd'), 24),\n",
       " (('s', 'w'), 24),\n",
       " (('s', 'n'), 24),\n",
       " (('h', 'd'), 24),\n",
       " (('w', 'h'), 23),\n",
       " (('y', 'j'), 23),\n",
       " (('y', 'y'), 23),\n",
       " (('r', 'z'), 23),\n",
       " (('d', 'w'), 23),\n",
       " (('w', 'r'), 22),\n",
       " (('t', 'n'), 22),\n",
       " (('l', 'f'), 22),\n",
       " (('y', 'h'), 22),\n",
       " (('r', 'w'), 21),\n",
       " (('s', 'b'), 21),\n",
       " (('m', 'n'), 20),\n",
       " (('f', 'l'), 20),\n",
       " (('w', 's'), 20),\n",
       " (('k', 'k'), 20),\n",
       " (('h', 'z'), 20),\n",
       " (('g', 'd'), 19),\n",
       " (('l', 'h'), 19),\n",
       " (('n', 'm'), 19),\n",
       " (('x', 'z'), 19),\n",
       " (('u', 'f'), 19),\n",
       " (('f', 't'), 18),\n",
       " (('l', 'r'), 18),\n",
       " (('p', 't'), 17),\n",
       " (('t', 'c'), 17),\n",
       " (('k', 't'), 17),\n",
       " (('d', 'v'), 17),\n",
       " (('u', 'p'), 16),\n",
       " (('p', 'l'), 16),\n",
       " (('l', 'w'), 16),\n",
       " (('p', 's'), 16),\n",
       " (('o', 'j'), 16),\n",
       " (('r', 'q'), 16),\n",
       " (('y', 'p'), 15),\n",
       " (('l', 'p'), 15),\n",
       " (('t', 'v'), 15),\n",
       " (('r', 'p'), 14),\n",
       " (('l', 'n'), 14),\n",
       " (('e', 'q'), 14),\n",
       " (('f', 'y'), 14),\n",
       " (('s', 'v'), 14),\n",
       " (('u', 'j'), 14),\n",
       " (('v', 'l'), 14),\n",
       " (('q', 'a'), 13),\n",
       " (('u', 'y'), 13),\n",
       " (('q', 'i'), 13),\n",
       " (('w', 'l'), 13),\n",
       " (('p', 'y'), 12),\n",
       " (('y', 'f'), 12),\n",
       " (('c', 'q'), 11),\n",
       " (('j', 'r'), 11),\n",
       " (('n', 'w'), 11),\n",
       " (('n', 'f'), 11),\n",
       " (('t', 'w'), 11),\n",
       " (('m', 'z'), 11),\n",
       " (('u', 'o'), 10),\n",
       " (('f', 'u'), 10),\n",
       " (('l', 'z'), 10),\n",
       " (('h', 'w'), 10),\n",
       " (('u', 'q'), 10),\n",
       " (('j', 'y'), 10),\n",
       " (('s', 'z'), 10),\n",
       " (('s', 'd'), 9),\n",
       " (('j', 'l'), 9),\n",
       " (('d', 'j'), 9),\n",
       " (('k', 'm'), 9),\n",
       " (('r', 'f'), 9),\n",
       " (('h', 'j'), 9),\n",
       " (('v', 'n'), 8),\n",
       " (('n', 'b'), 8),\n",
       " (('i', 'w'), 8),\n",
       " (('h', 'b'), 8),\n",
       " (('b', 's'), 8),\n",
       " (('w', 't'), 8),\n",
       " (('w', 'd'), 8),\n",
       " (('v', 'v'), 7),\n",
       " (('v', 'u'), 7),\n",
       " (('j', 's'), 7),\n",
       " (('m', 'j'), 7),\n",
       " (('f', 's'), 6),\n",
       " (('l', 'g'), 6),\n",
       " (('l', 'j'), 6),\n",
       " (('j', 'w'), 6),\n",
       " (('n', 'x'), 6),\n",
       " (('y', 'q'), 6),\n",
       " (('w', 'k'), 6),\n",
       " (('g', 'm'), 6),\n",
       " (('x', 'u'), 5),\n",
       " (('m', 'h'), 5),\n",
       " (('m', 'l'), 5),\n",
       " (('j', 'm'), 5),\n",
       " (('c', 's'), 5),\n",
       " (('j', 'v'), 5),\n",
       " (('n', 'p'), 5),\n",
       " (('d', 'f'), 5),\n",
       " (('x', 'd'), 5),\n",
       " (('z', 'b'), 4),\n",
       " (('f', 'n'), 4),\n",
       " (('x', 'c'), 4),\n",
       " (('m', 't'), 4),\n",
       " (('t', 'm'), 4),\n",
       " (('z', 'n'), 4),\n",
       " (('z', 't'), 4),\n",
       " (('p', 'u'), 4),\n",
       " (('c', 'z'), 4),\n",
       " (('b', 'n'), 4),\n",
       " (('z', 's'), 4),\n",
       " (('f', 'w'), 4),\n",
       " (('d', 't'), 4),\n",
       " (('j', 'd'), 4),\n",
       " (('j', 'c'), 4),\n",
       " (('y', 'w'), 4),\n",
       " (('v', 'k'), 3),\n",
       " (('x', 'w'), 3),\n",
       " (('t', 'j'), 3),\n",
       " (('c', 'j'), 3),\n",
       " (('q', 'w'), 3),\n",
       " (('g', 'b'), 3),\n",
       " (('o', 'q'), 3),\n",
       " (('r', 'x'), 3),\n",
       " (('d', 'c'), 3),\n",
       " (('g', 'j'), 3),\n",
       " (('x', 'f'), 3),\n",
       " (('z', 'w'), 3),\n",
       " (('d', 'k'), 3),\n",
       " (('u', 'u'), 3),\n",
       " (('m', 'v'), 3),\n",
       " (('c', 'x'), 3),\n",
       " (('l', 'q'), 3),\n",
       " (('p', 'b'), 2),\n",
       " (('t', 'g'), 2),\n",
       " (('q', 's'), 2),\n",
       " (('t', 'x'), 2),\n",
       " (('f', 'k'), 2),\n",
       " (('b', 't'), 2),\n",
       " (('j', 'n'), 2),\n",
       " (('k', 'c'), 2),\n",
       " (('z', 'k'), 2),\n",
       " (('s', 'j'), 2),\n",
       " (('s', 'f'), 2),\n",
       " (('z', 'j'), 2),\n",
       " (('n', 'q'), 2),\n",
       " (('f', 'z'), 2),\n",
       " (('h', 'g'), 2),\n",
       " (('w', 'w'), 2),\n",
       " (('k', 'j'), 2),\n",
       " (('j', 'k'), 2),\n",
       " (('w', 'm'), 2),\n",
       " (('z', 'c'), 2),\n",
       " (('z', 'v'), 2),\n",
       " (('w', 'f'), 2),\n",
       " (('q', 'm'), 2),\n",
       " (('k', 'z'), 2),\n",
       " (('j', 'j'), 2),\n",
       " (('z', 'p'), 2),\n",
       " (('j', 't'), 2),\n",
       " (('k', 'b'), 2),\n",
       " (('m', 'w'), 2),\n",
       " (('h', 'f'), 2),\n",
       " (('c', 'g'), 2),\n",
       " (('t', 'f'), 2),\n",
       " (('h', 'c'), 2),\n",
       " (('q', 'o'), 2),\n",
       " (('k', 'd'), 2),\n",
       " (('k', 'v'), 2),\n",
       " (('s', 'g'), 2),\n",
       " (('z', 'd'), 2),\n",
       " (('q', 'r'), 1),\n",
       " (('d', 'z'), 1),\n",
       " (('p', 'j'), 1),\n",
       " (('q', 'l'), 1),\n",
       " (('p', 'f'), 1),\n",
       " (('q', 'e'), 1),\n",
       " (('b', 'c'), 1),\n",
       " (('c', 'd'), 1),\n",
       " (('m', 'f'), 1),\n",
       " (('p', 'n'), 1),\n",
       " (('w', 'b'), 1),\n",
       " (('p', 'c'), 1),\n",
       " (('h', 'p'), 1),\n",
       " (('f', 'h'), 1),\n",
       " (('b', 'j'), 1),\n",
       " (('f', 'g'), 1),\n",
       " (('z', 'g'), 1),\n",
       " (('c', 'p'), 1),\n",
       " (('p', 'k'), 1),\n",
       " (('p', 'm'), 1),\n",
       " (('x', 'n'), 1),\n",
       " (('s', 'q'), 1),\n",
       " (('k', 'f'), 1),\n",
       " (('m', 'k'), 1),\n",
       " (('x', 'h'), 1),\n",
       " (('g', 'f'), 1),\n",
       " (('v', 'b'), 1),\n",
       " (('j', 'p'), 1),\n",
       " (('g', 'z'), 1),\n",
       " (('v', 'd'), 1),\n",
       " (('d', 'b'), 1),\n",
       " (('v', 'h'), 1),\n",
       " (('h', 'h'), 1),\n",
       " (('g', 'v'), 1),\n",
       " (('d', 'q'), 1),\n",
       " (('x', 'b'), 1),\n",
       " (('w', 'z'), 1),\n",
       " (('h', 'q'), 1),\n",
       " (('j', 'b'), 1),\n",
       " (('x', 'm'), 1),\n",
       " (('w', 'g'), 1),\n",
       " (('t', 'b'), 1),\n",
       " (('z', 'x'), 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_dict = {}\n",
    "for word in names:\n",
    "    word =  ['.'] + list(word) + ['.']\n",
    "    for char1, char2 in zip(word, word[1:]):\n",
    "        bigram = (char1,char2)\n",
    "        bigram_dict[bigram] = bigram_dict.get(bigram, 0)+1\n",
    "\n",
    "# lets see the most likely bigrams by sorting the bigram dict according to the values of the bigrams\n",
    "sorted(bigram_dict.items(), key= lambda kv: -kv[1])\n",
    "# print(bigram_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would create a two dimesional tensor which we would use to map the numbers of times one char in a bigram follows the second character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 27])\n"
     ]
    }
   ],
   "source": [
    "bigram_tensor = torch.zeros((27,27), dtype = torch.int32)\n",
    "print(bigram_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would map the number of occurences of one character after the other in the 2D array. Using the chartoidx dict and idxtochar dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 4410, 1306, 1542, 1690, 1531,  417,  669,  874,  591, 2422, 2963,\n",
       "         1572, 2538, 1146,  394,  515,   92, 1639, 2055, 1308,   78,  376,  307,\n",
       "          134,  535,  929],\n",
       "        [6640,  556,  541,  470, 1042,  692,  134,  168, 2332, 1650,  175,  568,\n",
       "         2528, 1634, 5438,   63,   82,   60, 3264, 1118,  687,  381,  834,  161,\n",
       "          182, 2050,  435],\n",
       "        [ 114,  321,   38,    1,   65,  655,    0,    0,   41,  217,    1,    0,\n",
       "          103,    0,    4,  105,    0,    0,  842,    8,    2,   45,    0,    0,\n",
       "            0,   83,    0],\n",
       "        [  97,  815,    0,   42,    1,  551,    0,    2,  664,  271,    3,  316,\n",
       "          116,    0,    0,  380,    1,   11,   76,    5,   35,   35,    0,    0,\n",
       "            3,  104,    4],\n",
       "        [ 516, 1303,    1,    3,  149, 1283,    5,   25,  118,  674,    9,    3,\n",
       "           60,   30,   31,  378,    0,    1,  424,   29,    4,   92,   17,   23,\n",
       "            0,  317,    1],\n",
       "        [3983,  679,  121,  153,  384, 1271,   82,  125,  152,  818,   55,  178,\n",
       "         3248,  769, 2675,  269,   83,   14, 1958,  861,  580,   69,  463,   50,\n",
       "          132, 1070,  181],\n",
       "        [  80,  242,    0,    0,    0,  123,   44,    1,    1,  160,    0,    2,\n",
       "           20,    0,    4,   60,    0,    0,  114,    6,   18,   10,    0,    4,\n",
       "            0,   14,    2],\n",
       "        [ 108,  330,    3,    0,   19,  334,    1,   25,  360,  190,    3,    0,\n",
       "           32,    6,   27,   83,    0,    0,  201,   30,   31,   85,    1,   26,\n",
       "            0,   31,    1],\n",
       "        [2409, 2244,    8,    2,   24,  674,    2,    2,    1,  729,    9,   29,\n",
       "          185,  117,  138,  287,    1,    1,  204,   31,   71,  166,   39,   10,\n",
       "            0,  213,   20],\n",
       "        [2489, 2445,  110,  509,  440, 1653,  101,  428,   95,   82,   76,  445,\n",
       "         1345,  427, 2126,  588,   53,   52,  849, 1316,  541,  109,  269,    8,\n",
       "           89,  779,  277],\n",
       "        [  71, 1473,    1,    4,    4,  440,    0,    0,   45,  119,    2,    2,\n",
       "            9,    5,    2,  479,    1,    0,   11,    7,    2,  202,    5,    6,\n",
       "            0,   10,    0],\n",
       "        [ 363, 1731,    2,    2,    2,  895,    1,    0,  307,  509,    2,   20,\n",
       "          139,    9,   26,  344,    0,    0,  109,   95,   17,   50,    2,   34,\n",
       "            0,  379,    2],\n",
       "        [1314, 2623,   52,   25,  138, 2921,   22,    6,   19, 2480,    6,   24,\n",
       "         1345,   60,   14,  692,   15,    3,   18,   94,   77,  324,   72,   16,\n",
       "            0, 1588,   10],\n",
       "        [ 516, 2590,  112,   51,   24,  818,    1,    0,    5, 1256,    7,    1,\n",
       "            5,  168,   20,  452,   38,    0,   97,   35,    4,  139,    3,    2,\n",
       "            0,  287,   11],\n",
       "        [6763, 2977,    8,  213,  704, 1359,   11,  273,   26, 1725,   44,   58,\n",
       "          195,   19, 1906,  496,    5,    2,   44,  278,  443,   96,   55,   11,\n",
       "            6,  465,  145],\n",
       "        [ 855,  149,  140,  114,  190,  132,   34,   44,  171,   69,   16,   68,\n",
       "          619,  261, 2411,  115,   95,    3, 1059,  504,  118,  275,  176,  114,\n",
       "           45,  103,   54],\n",
       "        [  33,  209,    2,    1,    0,  197,    1,    0,  204,   61,    1,    1,\n",
       "           16,    1,    1,   59,   39,    0,  151,   16,   17,    4,    0,    0,\n",
       "            0,   12,    0],\n",
       "        [  28,   13,    0,    0,    0,    1,    0,    0,    0,   13,    0,    0,\n",
       "            1,    2,    0,    2,    0,    0,    1,    2,    0,  206,    0,    3,\n",
       "            0,    0,    0],\n",
       "        [1377, 2356,   41,   99,  187, 1697,    9,   76,  121, 3033,   25,   90,\n",
       "          413,  162,  140,  869,   14,   16,  425,  190,  208,  252,   80,   21,\n",
       "            3,  773,   23],\n",
       "        [1169, 1201,   21,   60,    9,  884,    2,    2, 1285,  684,    2,   82,\n",
       "          279,   90,   24,  531,   51,    1,   55,  461,  765,  185,   14,   24,\n",
       "            0,  215,   10],\n",
       "        [ 483, 1027,    1,   17,    0,  716,    2,    2,  647,  532,    3,    0,\n",
       "          134,    4,   22,  667,    0,    0,  352,   35,  374,   78,   15,   11,\n",
       "            2,  341,  105],\n",
       "        [ 155,  163,  103,  103,  136,  169,   19,   47,   58,  121,   14,   93,\n",
       "          301,  154,  275,   10,   16,   10,  414,  474,   82,    3,   37,   86,\n",
       "           34,   13,   45],\n",
       "        [  88,  642,    1,    0,    1,  568,    0,    0,    1,  911,    0,    3,\n",
       "           14,    0,    8,  153,    0,    0,   48,    0,    0,    7,    7,    0,\n",
       "            0,  121,    0],\n",
       "        [  51,  280,    1,    0,    8,  149,    2,    1,   23,  148,    0,    6,\n",
       "           13,    2,   58,   36,    0,    0,   22,   20,    8,   25,    0,    2,\n",
       "            0,   73,    1],\n",
       "        [ 164,  103,    1,    4,    5,   36,    3,    0,    1,  102,    0,    0,\n",
       "           39,    1,    1,   41,    0,    0,    0,   31,   70,    5,    0,    3,\n",
       "           38,   30,   19],\n",
       "        [2007, 2143,   27,  115,  272,  301,   12,   30,   22,  192,   23,   86,\n",
       "         1104,  148, 1826,  271,   15,    6,  291,  401,  104,  141,  106,    4,\n",
       "           28,   23,   78],\n",
       "        [ 160,  860,    4,    2,    2,  373,    0,    1,   43,  364,    2,    2,\n",
       "          123,   35,    4,  110,    2,    0,   32,    4,    4,   73,    2,    3,\n",
       "            1,  147,   45]], dtype=torch.int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key, value in bigram_dict.items():\n",
    "    char1, char2 = key\n",
    "    ch1_idx, ch2_idx = chartoidx[char1], chartoidx[char2]\n",
    "    bigram_tensor[ch1_idx][ch2_idx] = value\n",
    "bigram_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{y}%{x}<br>%{z}",
         "type": "heatmap",
         "x": [
          ".",
          "a",
          "b",
          "c",
          "d",
          "e",
          "f",
          "g",
          "h",
          "i",
          "j",
          "k",
          "l",
          "m",
          "n",
          "o",
          "p",
          "q",
          "r",
          "s",
          "t",
          "u",
          "v",
          "w",
          "x",
          "y",
          "z"
         ],
         "xaxis": "x",
         "y": [
          ".",
          "a",
          "b",
          "c",
          "d",
          "e",
          "f",
          "g",
          "h",
          "i",
          "j",
          "k",
          "l",
          "m",
          "n",
          "o",
          "p",
          "q",
          "r",
          "s",
          "t",
          "u",
          "v",
          "w",
          "x",
          "y",
          "z"
         ],
         "yaxis": "y",
         "z": [
          [
           0,
           4410,
           1306,
           1542,
           1690,
           1531,
           417,
           669,
           874,
           591,
           2422,
           2963,
           1572,
           2538,
           1146,
           394,
           515,
           92,
           1639,
           2055,
           1308,
           78,
           376,
           307,
           134,
           535,
           929
          ],
          [
           6640,
           556,
           541,
           470,
           1042,
           692,
           134,
           168,
           2332,
           1650,
           175,
           568,
           2528,
           1634,
           5438,
           63,
           82,
           60,
           3264,
           1118,
           687,
           381,
           834,
           161,
           182,
           2050,
           435
          ],
          [
           114,
           321,
           38,
           1,
           65,
           655,
           0,
           0,
           41,
           217,
           1,
           0,
           103,
           0,
           4,
           105,
           0,
           0,
           842,
           8,
           2,
           45,
           0,
           0,
           0,
           83,
           0
          ],
          [
           97,
           815,
           0,
           42,
           1,
           551,
           0,
           2,
           664,
           271,
           3,
           316,
           116,
           0,
           0,
           380,
           1,
           11,
           76,
           5,
           35,
           35,
           0,
           0,
           3,
           104,
           4
          ],
          [
           516,
           1303,
           1,
           3,
           149,
           1283,
           5,
           25,
           118,
           674,
           9,
           3,
           60,
           30,
           31,
           378,
           0,
           1,
           424,
           29,
           4,
           92,
           17,
           23,
           0,
           317,
           1
          ],
          [
           3983,
           679,
           121,
           153,
           384,
           1271,
           82,
           125,
           152,
           818,
           55,
           178,
           3248,
           769,
           2675,
           269,
           83,
           14,
           1958,
           861,
           580,
           69,
           463,
           50,
           132,
           1070,
           181
          ],
          [
           80,
           242,
           0,
           0,
           0,
           123,
           44,
           1,
           1,
           160,
           0,
           2,
           20,
           0,
           4,
           60,
           0,
           0,
           114,
           6,
           18,
           10,
           0,
           4,
           0,
           14,
           2
          ],
          [
           108,
           330,
           3,
           0,
           19,
           334,
           1,
           25,
           360,
           190,
           3,
           0,
           32,
           6,
           27,
           83,
           0,
           0,
           201,
           30,
           31,
           85,
           1,
           26,
           0,
           31,
           1
          ],
          [
           2409,
           2244,
           8,
           2,
           24,
           674,
           2,
           2,
           1,
           729,
           9,
           29,
           185,
           117,
           138,
           287,
           1,
           1,
           204,
           31,
           71,
           166,
           39,
           10,
           0,
           213,
           20
          ],
          [
           2489,
           2445,
           110,
           509,
           440,
           1653,
           101,
           428,
           95,
           82,
           76,
           445,
           1345,
           427,
           2126,
           588,
           53,
           52,
           849,
           1316,
           541,
           109,
           269,
           8,
           89,
           779,
           277
          ],
          [
           71,
           1473,
           1,
           4,
           4,
           440,
           0,
           0,
           45,
           119,
           2,
           2,
           9,
           5,
           2,
           479,
           1,
           0,
           11,
           7,
           2,
           202,
           5,
           6,
           0,
           10,
           0
          ],
          [
           363,
           1731,
           2,
           2,
           2,
           895,
           1,
           0,
           307,
           509,
           2,
           20,
           139,
           9,
           26,
           344,
           0,
           0,
           109,
           95,
           17,
           50,
           2,
           34,
           0,
           379,
           2
          ],
          [
           1314,
           2623,
           52,
           25,
           138,
           2921,
           22,
           6,
           19,
           2480,
           6,
           24,
           1345,
           60,
           14,
           692,
           15,
           3,
           18,
           94,
           77,
           324,
           72,
           16,
           0,
           1588,
           10
          ],
          [
           516,
           2590,
           112,
           51,
           24,
           818,
           1,
           0,
           5,
           1256,
           7,
           1,
           5,
           168,
           20,
           452,
           38,
           0,
           97,
           35,
           4,
           139,
           3,
           2,
           0,
           287,
           11
          ],
          [
           6763,
           2977,
           8,
           213,
           704,
           1359,
           11,
           273,
           26,
           1725,
           44,
           58,
           195,
           19,
           1906,
           496,
           5,
           2,
           44,
           278,
           443,
           96,
           55,
           11,
           6,
           465,
           145
          ],
          [
           855,
           149,
           140,
           114,
           190,
           132,
           34,
           44,
           171,
           69,
           16,
           68,
           619,
           261,
           2411,
           115,
           95,
           3,
           1059,
           504,
           118,
           275,
           176,
           114,
           45,
           103,
           54
          ],
          [
           33,
           209,
           2,
           1,
           0,
           197,
           1,
           0,
           204,
           61,
           1,
           1,
           16,
           1,
           1,
           59,
           39,
           0,
           151,
           16,
           17,
           4,
           0,
           0,
           0,
           12,
           0
          ],
          [
           28,
           13,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           13,
           0,
           0,
           1,
           2,
           0,
           2,
           0,
           0,
           1,
           2,
           0,
           206,
           0,
           3,
           0,
           0,
           0
          ],
          [
           1377,
           2356,
           41,
           99,
           187,
           1697,
           9,
           76,
           121,
           3033,
           25,
           90,
           413,
           162,
           140,
           869,
           14,
           16,
           425,
           190,
           208,
           252,
           80,
           21,
           3,
           773,
           23
          ],
          [
           1169,
           1201,
           21,
           60,
           9,
           884,
           2,
           2,
           1285,
           684,
           2,
           82,
           279,
           90,
           24,
           531,
           51,
           1,
           55,
           461,
           765,
           185,
           14,
           24,
           0,
           215,
           10
          ],
          [
           483,
           1027,
           1,
           17,
           0,
           716,
           2,
           2,
           647,
           532,
           3,
           0,
           134,
           4,
           22,
           667,
           0,
           0,
           352,
           35,
           374,
           78,
           15,
           11,
           2,
           341,
           105
          ],
          [
           155,
           163,
           103,
           103,
           136,
           169,
           19,
           47,
           58,
           121,
           14,
           93,
           301,
           154,
           275,
           10,
           16,
           10,
           414,
           474,
           82,
           3,
           37,
           86,
           34,
           13,
           45
          ],
          [
           88,
           642,
           1,
           0,
           1,
           568,
           0,
           0,
           1,
           911,
           0,
           3,
           14,
           0,
           8,
           153,
           0,
           0,
           48,
           0,
           0,
           7,
           7,
           0,
           0,
           121,
           0
          ],
          [
           51,
           280,
           1,
           0,
           8,
           149,
           2,
           1,
           23,
           148,
           0,
           6,
           13,
           2,
           58,
           36,
           0,
           0,
           22,
           20,
           8,
           25,
           0,
           2,
           0,
           73,
           1
          ],
          [
           164,
           103,
           1,
           4,
           5,
           36,
           3,
           0,
           1,
           102,
           0,
           0,
           39,
           1,
           1,
           41,
           0,
           0,
           0,
           31,
           70,
           5,
           0,
           3,
           38,
           30,
           19
          ],
          [
           2007,
           2143,
           27,
           115,
           272,
           301,
           12,
           30,
           22,
           192,
           23,
           86,
           1104,
           148,
           1826,
           271,
           15,
           6,
           291,
           401,
           104,
           141,
           106,
           4,
           28,
           23,
           78
          ],
          [
           160,
           860,
           4,
           2,
           2,
           373,
           0,
           1,
           43,
           364,
           2,
           2,
           123,
           35,
           4,
           110,
           2,
           0,
           32,
           4,
           4,
           73,
           2,
           3,
           1,
           147,
           45
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(247,251,255)"
          ],
          [
           0.125,
           "rgb(222,235,247)"
          ],
          [
           0.25,
           "rgb(198,219,239)"
          ],
          [
           0.375,
           "rgb(158,202,225)"
          ],
          [
           0.5,
           "rgb(107,174,214)"
          ],
          [
           0.625,
           "rgb(66,146,198)"
          ],
          [
           0.75,
           "rgb(33,113,181)"
          ],
          [
           0.875,
           "rgb(8,81,156)"
          ],
          [
           1,
           "rgb(8,48,107)"
          ]
         ],
         "showscale": false
        },
        "height": 700,
        "margin": {
         "b": 50,
         "l": 0,
         "r": 0,
         "t": 50
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now would write some plotly code to visualize the bigrams tensor\n",
    "x = px.imshow(bigram_tensor, x = list(chartoidx.keys()),\n",
    "                     y = list(chartoidx.keys()),\n",
    "                      color_continuous_scale='blues',\n",
    "                      width= 800,\n",
    "                      height = 700,\n",
    "                      \n",
    "                      )\n",
    "x.update_traces(texttemplate = \"%{y}%{x}<br>%{z}\")\n",
    "x.update_layout(margin=dict(l=0, r=0, t=50, b=50))\n",
    "x.update_coloraxes(showscale = False)\n",
    "x.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 4410, 1306, 1542, 1690, 1531,  417,  669,  874,  591, 2422, 2963,\n",
       "        1572, 2538, 1146,  394,  515,   92, 1639, 2055, 1308,   78,  376,  307,\n",
       "         134,  535,  929], dtype=torch.int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The raw counts of the bigrams are given below\n",
    "bigram_tensor[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we will do not is that we would convert these raw count to probabilites i.e they should sum to 1 and then we will sample from these probabbilities and get text which is according to this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,\n",
       "        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,\n",
       "        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To create a probability distribution here we will have to divide the above values by their sum.\n",
    "# This gives us probability of every single character to be the first character.\n",
    "prob_tensor = bigram_tensor[0].float()/ bigram_tensor[0].sum()\n",
    "prob_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To sample from this distruibution we would do a torch.multinomial which generates samples from a given probability distribution.\n",
    "# To make everything deterministic we would use a pytorch generator.\n",
    "generator = torch.Generator().manual_seed(2147483647+1)\n",
    "# Now we will get samples from the prob_tensor distribution using the generator for determinism. We would sample once from the distribution.\n",
    "# The number that we sample from this distribution will be the index from this distribution\n",
    "ix = torch.multinomial(prob_tensor, generator=generator, num_samples=1, replacement=True).item()\n",
    "# We can map the index of the character from the index to the character to generate a letter from the index\n",
    "char = idxtochar[ix]\n",
    "# similarly we can generate other indexes and to sample the next character after m.\n",
    "char"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one inefficiency here is that we are sampling again and again the counts matrix and then converting to the probability distribution. What we need to do is that we need to convert the whole counts array to the probability distribution to not do conversion again and again and directly sample from the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigram_tensor.sum() # But we do not want this because it takes the sum of all the counts in the matrix.\n",
    "# Instead what we need to do is that we need to get the probabilities of the rows. So we will do sum(dim=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 1])\n"
     ]
    }
   ],
   "source": [
    "sum_array = bigram_tensor.sum(dim=1, keepdims = True)\n",
    "print(sum_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 27])\n",
      "tensor(1.0008)\n"
     ]
    }
   ],
   "source": [
    "# Now we would need to divide the whole matrix by the sum_array.\n",
    "p_matrix = (bigram_tensor.float()+1)/sum_array\n",
    "print(p_matrix.shape)\n",
    "print(p_matrix[0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{y}%{x}<br>%{z}",
         "type": "heatmap",
         "x": [
          ".",
          "a",
          "b",
          "c",
          "d",
          "e",
          "f",
          "g",
          "h",
          "i",
          "j",
          "k",
          "l",
          "m",
          "n",
          "o",
          "p",
          "q",
          "r",
          "s",
          "t",
          "u",
          "v",
          "w",
          "x",
          "y",
          "z"
         ],
         "xaxis": "x",
         "y": [
          ".",
          "a",
          "b",
          "c",
          "d",
          "e",
          "f",
          "g",
          "h",
          "i",
          "j",
          "k",
          "l",
          "m",
          "n",
          "o",
          "p",
          "q",
          "r",
          "s",
          "t",
          "u",
          "v",
          "w",
          "x",
          "y",
          "z"
         ],
         "yaxis": "y",
         "z": [
          [
           0.00003121780537185259,
           0.13770174980163574,
           0.040801674127578735,
           0.048169076442718506,
           0.05278931185603142,
           0.04782567918300629,
           0.013049042783677578,
           0.020915931090712547,
           0.02731558121740818,
           0.018480941653251648,
           0.07564074546098709,
           0.09252957999706268,
           0.04910561069846153,
           0.07926201075315475,
           0.03580682352185249,
           0.012331034056842327,
           0.01610838808119297,
           0.0029032560996711254,
           0.05119720473885536,
           0.064183808863163,
           0.04086410999298096,
           0.0024662066716700792,
           0.011769113130867481,
           0.009615084156394005,
           0.004214403685182333,
           0.016732744872570038,
           0.02903256006538868
          ],
          [
           0.19598641991615295,
           0.01643795147538185,
           0.01599527895450592,
           0.01389995589852333,
           0.030780581757426262,
           0.02045152708888054,
           0.0039840638637542725,
           0.004987457767128944,
           0.06885052472352982,
           0.048723623156547546,
           0.0051940386183559895,
           0.016792090609669685,
           0.07463479787111282,
           0.0482514388859272,
           0.1605135053396225,
           0.00188874127343297,
           0.002449461491778493,
           0.0018002066062763333,
           0.09635531902313232,
           0.03302346169948578,
           0.020303970202803612,
           0.011273425072431564,
           0.02464217133820057,
           0.004780876450240612,
           0.005400619935244322,
           0.06052825599908829,
           0.012867050245404243
          ],
          [
           0.043478261679410934,
           0.12173912674188614,
           0.014744801446795464,
           0.0007561436505056918,
           0.024952741339802742,
           0.2480151206254959,
           0.0003780718252528459,
           0.0003780718252528459,
           0.015879016369581223,
           0.08241965621709824,
           0.0007561436505056918,
           0.0003780718252528459,
           0.0393194705247879,
           0.0003780718252528459,
           0.0018903592135757208,
           0.04007561504840851,
           0.0003780718252528459,
           0.0003780718252528459,
           0.31871455907821655,
           0.0034026463981717825,
           0.001134215504862368,
           0.017391303554177284,
           0.0003780718252528459,
           0.0003780718252528459,
           0.0003780718252528459,
           0.031758032739162445,
           0.0003780718252528459
          ],
          [
           0.02774631977081299,
           0.23103058338165283,
           0.00028312570066191256,
           0.01217440515756607,
           0.0005662514013238251,
           0.1562853902578354,
           0.00028312570066191256,
           0.0008493771310895681,
           0.18827860057353973,
           0.07701019197702408,
           0.0011325028026476502,
           0.08975084871053696,
           0.033125706017017365,
           0.00028312570066191256,
           0.00028312570066191256,
           0.10787089169025421,
           0.0005662514013238251,
           0.0033975085243582726,
           0.021800680086016655,
           0.0016987542621791363,
           0.010192525573074818,
           0.010192525573074818,
           0.00028312570066191256,
           0.00028312570066191256,
           0.0011325028026476502,
           0.029728198423981667,
           0.0014156285906210542
          ],
          [
           0.09406841546297073,
           0.23726347088813782,
           0.00036390102468430996,
           0.0007278020493686199,
           0.02729257568717003,
           0.23362445831298828,
           0.0010917030740529299,
           0.004730713088065386,
           0.021652109920978546,
           0.12281659245491028,
           0.0018195051234215498,
           0.0007278020493686199,
           0.011098980903625488,
           0.0056404657661914825,
           0.005822416394948959,
           0.06895924359560013,
           0.00018195051234215498,
           0.00036390102468430996,
           0.07732896506786346,
           0.005458515137434006,
           0.0009097525617107749,
           0.016921397298574448,
           0.0032751092221587896,
           0.0043668122962117195,
           0.00018195051234215498,
           0.05786026269197464,
           0.00036390102468430996
          ],
          [
           0.1950741857290268,
           0.03329579532146454,
           0.005973657127469778,
           0.007540517952293158,
           0.018851295113563538,
           0.06228271871805191,
           0.0040640453808009624,
           0.0061695147305727005,
           0.007491553667932749,
           0.04010184481739998,
           0.002742006676271558,
           0.008764628320932388,
           0.15908534824848175,
           0.037702590227127075,
           0.13102874159812927,
           0.013220388442277908,
           0.004113009665161371,
           0.0007344660698436201,
           0.09592126309871674,
           0.04220731556415558,
           0.02844831719994545,
           0.0034275082871317863,
           0.022719483822584152,
           0.002497184555977583,
           0.006512265652418137,
           0.05244087427854538,
           0.008911521174013615
          ],
          [
           0.08950275927782059,
           0.26850828528404236,
           0.0011049723252654076,
           0.0011049723252654076,
           0.0011049723252654076,
           0.13701657950878143,
           0.049723755568265915,
           0.002209944650530815,
           0.002209944650530815,
           0.1779005527496338,
           0.0011049723252654076,
           0.0033149172086268663,
           0.023204419761896133,
           0.0011049723252654076,
           0.005524862091988325,
           0.06740331649780273,
           0.0011049723252654076,
           0.0011049723252654076,
           0.1270718276500702,
           0.00773480674251914,
           0.02099447511136532,
           0.012154696509242058,
           0.0011049723252654076,
           0.005524862091988325,
           0.0011049723252654076,
           0.016574585810303688,
           0.0033149172086268663
          ],
          [
           0.056564606726169586,
           0.17176958918571472,
           0.0020757655147463083,
           0.0005189413786865771,
           0.010378827340900898,
           0.1738453507423401,
           0.0010378827573731542,
           0.013492475263774395,
           0.18733783066272736,
           0.09911780059337616,
           0.0020757655147463083,
           0.0005189413786865771,
           0.017125064507126808,
           0.003632589476183057,
           0.014530357904732227,
           0.04359107464551926,
           0.0005189413786865771,
           0.0005189413786865771,
           0.10482615232467651,
           0.016087181866168976,
           0.016606124117970467,
           0.04462895542383194,
           0.0010378827573731542,
           0.014011416584253311,
           0.0005189413786865771,
           0.016606124117970467,
           0.0010378827573731542
          ],
          [
           0.31643906235694885,
           0.2947741448879242,
           0.001181722735054791,
           0.00039390756865032017,
           0.0032825630623847246,
           0.08862920105457306,
           0.00039390756865032017,
           0.00039390756865032017,
           0.00026260505546815693,
           0.09585084021091461,
           0.0013130252482369542,
           0.0039390758611261845,
           0.02442226931452751,
           0.015493697486817837,
           0.018251050263643265,
           0.03781512752175331,
           0.00026260505546815693,
           0.00026260505546815693,
           0.02691701613366604,
           0.004201680887490511,
           0.009453781880438328,
           0.021927520632743835,
           0.005252100992947817,
           0.0014443277614191175,
           0.00013130252773407847,
           0.028098739683628082,
           0.0027573530096560717
          ],
          [
           0.1406700164079666,
           0.13818427920341492,
           0.006270832382142544,
           0.028811931610107422,
           0.02491384744644165,
           0.09344104677438736,
           0.0057623861357569695,
           0.02423591911792755,
           0.005423422437161207,
           0.0046890005469322205,
           0.004350036848336458,
           0.025196315720677376,
           0.07604090124368668,
           0.024179425090551376,
           0.12016270309686661,
           0.03327495604753494,
           0.0030506751500070095,
           0.0029941811226308346,
           0.0480198860168457,
           0.0744025781750679,
           0.03061973862349987,
           0.006214338354766369,
           0.01525337528437376,
           0.000508445838931948,
           0.005084458272904158,
           0.04406530782580376,
           0.015705326572060585
          ],
          [
           0.024827586486935616,
           0.5082758665084839,
           0.0006896551931276917,
           0.0017241379246115685,
           0.0017241379246115685,
           0.15206897258758545,
           0.00034482759656384587,
           0.00034482759656384587,
           0.01586206816136837,
           0.04137931019067764,
           0.0010344827314838767,
           0.0010344827314838767,
           0.003448275849223137,
           0.0020689654629677534,
           0.0010344827314838767,
           0.16551724076271057,
           0.0006896551931276917,
           0.00034482759656384587,
           0.004137930925935507,
           0.002758620772510767,
           0.0010344827314838767,
           0.07000000029802322,
           0.0020689654629677534,
           0.0024137930013239384,
           0.00034482759656384587,
           0.003793103387579322,
           0.00034482759656384587
          ],
          [
           0.07222222536802292,
           0.34365078806877136,
           0.0005952381179668009,
           0.0005952381179668009,
           0.0005952381179668009,
           0.17777778208255768,
           0.00039682540227659047,
           0.00019841270113829523,
           0.06111111119389534,
           0.1011904776096344,
           0.0005952381179668009,
           0.004166666883975267,
           0.02777777798473835,
           0.0019841270986944437,
           0.0053571430034935474,
           0.0684523805975914,
           0.00019841270113829523,
           0.00019841270113829523,
           0.02182539738714695,
           0.01904761977493763,
           0.0035714285913854837,
           0.010119047947227955,
           0.0005952381179668009,
           0.0069444444961845875,
           0.00019841270113829523,
           0.075396828353405,
           0.0005952381179668009
          ],
          [
           0.09421120584011078,
           0.18799254298210144,
           0.0037971055135130882,
           0.0018627310637384653,
           0.009958446957170963,
           0.20934231579303741,
           0.001647800556384027,
           0.000501504517160356,
           0.0014328700490295887,
           0.17774753272533417,
           0.000501504517160356,
           0.0017910875612869859,
           0.0964321568608284,
           0.004370253533124924,
           0.0010746525367721915,
           0.0496489480137825,
           0.001146296039223671,
           0.00028657400980591774,
           0.0013612265465781093,
           0.006806132849305868,
           0.005588192958384752,
           0.02328413724899292,
           0.005229975562542677,
           0.0012179395416751504,
           0.00007164350245147943,
           0.11384152621030807,
           0.0007880785269662738
          ],
          [
           0.0778380036354065,
           0.3900933563709259,
           0.0170129481703043,
           0.007828966714441776,
           0.003763926448300481,
           0.12330622971057892,
           0.00030111410887911916,
           0.00015055705443955958,
           0.0009033423848450184,
           0.18925023078918457,
           0.0012044564355164766,
           0.00030111410887911916,
           0.0009033423848450184,
           0.025444142520427704,
           0.0031616983469575644,
           0.06820234656333923,
           0.005871725268661976,
           0.00015055705443955958,
           0.014754592441022396,
           0.00542005430907011,
           0.0007527853013016284,
           0.021077988669276237,
           0.0006022282177582383,
           0.0004516711924225092,
           0.00015055705443955958,
           0.04336043447256088,
           0.0018066847696900368
          ],
          [
           0.36907294392585754,
           0.16249249875545502,
           0.0004910787101835012,
           0.011676761321723461,
           0.03846783563494682,
           0.07420745491981506,
           0.0006547716329805553,
           0.014950619079172611,
           0.0014732362469658256,
           0.09417799115180969,
           0.00245539378374815,
           0.0032192938961088657,
           0.010694603435695171,
           0.0010912860743701458,
           0.10405413061380386,
           0.027118459343910217,
           0.00032738581649027765,
           0.00016369290824513882,
           0.00245539378374815,
           0.01522344071418047,
           0.02422655187547207,
           0.005292737390846014,
           0.0030556009151041508,
           0.0006547716329805553,
           0.00038195011438801885,
           0.025426965206861496,
           0.007966388016939163
          ],
          [
           0.10789009183645248,
           0.01890597492456436,
           0.017771616578102112,
           0.014494580216705799,
           0.024073606356978416,
           0.016763297840952873,
           0.004411393776535988,
           0.005671792197972536,
           0.021678850054740906,
           0.008822787553071976,
           0.0021426770836114883,
           0.008696747943758965,
           0.07814469188451767,
           0.0330224335193634,
           0.3040080666542053,
           0.01462061982601881,
           0.012099823914468288,
           0.0005041593103669584,
           0.13360221683979034,
           0.06365011632442474,
           0.014998739585280418,
           0.03478699177503586,
           0.02230904996395111,
           0.014494580216705799,
           0.0057978322729468346,
           0.013108141720294952,
           0.006932190619409084
          ],
          [
           0.03313840180635452,
           0.20467835664749146,
           0.002923976629972458,
           0.001949317753314972,
           0.000974658876657486,
           0.19298245012760162,
           0.001949317753314972,
           0.000974658876657486,
           0.19980506598949432,
           0.06042885035276413,
           0.001949317753314972,
           0.001949317753314972,
           0.01656920090317726,
           0.001949317753314972,
           0.001949317753314972,
           0.05847953259944916,
           0.03898635506629944,
           0.000974658876657486,
           0.14814814925193787,
           0.01656920090317726,
           0.017543859779834747,
           0.00487329438328743,
           0.000974658876657486,
           0.000974658876657486,
           0.000974658876657486,
           0.012670565396547318,
           0.000974658876657486
          ],
          [
           0.10661764442920685,
           0.05147058889269829,
           0.0036764706019312143,
           0.0036764706019312143,
           0.0036764706019312143,
           0.007352941203862429,
           0.0036764706019312143,
           0.0036764706019312143,
           0.0036764706019312143,
           0.05147058889269829,
           0.0036764706019312143,
           0.0036764706019312143,
           0.007352941203862429,
           0.011029412038624287,
           0.0036764706019312143,
           0.011029412038624287,
           0.0036764706019312143,
           0.0036764706019312143,
           0.007352941203862429,
           0.011029412038624287,
           0.0036764706019312143,
           0.7610294222831726,
           0.0036764706019312143,
           0.014705882407724857,
           0.0036764706019312143,
           0.0036764706019312143,
           0.0036764706019312143
          ],
          [
           0.10850393772125244,
           0.18559055030345917,
           0.0033070866484194994,
           0.007874015718698502,
           0.014803149737417698,
           0.13370078802108765,
           0.0007874015718698502,
           0.006062991917133331,
           0.009606298990547657,
           0.2388976365327835,
           0.002047243993729353,
           0.007165354210883379,
           0.03259842470288277,
           0.012834645807743073,
           0.011102362535893917,
           0.06850393861532211,
           0.0011811023578047752,
           0.001338582718744874,
           0.03354330733418465,
           0.015039370395243168,
           0.016456693410873413,
           0.019921259954571724,
           0.006377952639013529,
           0.001732283504679799,
           0.00031496063456870615,
           0.06094488129019737,
           0.001889763749204576
          ],
          [
           0.14433753490447998,
           0.14828522503376007,
           0.002714039059355855,
           0.00752528989687562,
           0.0012336540967226028,
           0.10917838662862778,
           0.0003700962115544826,
           0.0003700962115544826,
           0.15864790976047516,
           0.08450530469417572,
           0.0003700962115544826,
           0.010239329189062119,
           0.03454231470823288,
           0.011226251721382141,
           0.003084135241806507,
           0.06563039869070053,
           0.00641500111669302,
           0.0002467308077029884,
           0.0069084628485143185,
           0.05699481815099716,
           0.09449790418148041,
           0.022945966571569443,
           0.0018504811450839043,
           0.003084135241806507,
           0.0001233654038514942,
           0.02664692886173725,
           0.0013570195296779275
          ],
          [
           0.08689407259225845,
           0.1845601499080658,
           0.0003590664127841592,
           0.0032315978314727545,
           0.0001795332063920796,
           0.1287253201007843,
           0.0005385996191762388,
           0.0005385996191762388,
           0.11633752286434174,
           0.09569120407104492,
           0.0007181328255683184,
           0.0001795332063920796,
           0.02423698455095291,
           0.0008976660901680589,
           0.004129264038056135,
           0.11992818862199783,
           0.0001795332063920796,
           0.0001795332063920796,
           0.06337522715330124,
           0.006463195662945509,
           0.06732495874166489,
           0.014183123596012592,
           0.0028725313022732735,
           0.002154398476704955,
           0.0005385996191762388,
           0.06140035763382912,
           0.01903052069246769
          ],
          [
           0.049760766327381134,
           0.05231260135769844,
           0.03317384421825409,
           0.03317384421825409,
           0.04370015859603882,
           0.054226476699113846,
           0.00637958524748683,
           0.015311004593968391,
           0.0188197772949934,
           0.038915470242500305,
           0.0047846888191998005,
           0.02998405136168003,
           0.09633173793554306,
           0.049441784620285034,
           0.08803828060626984,
           0.003508772002533078,
           0.005422647576779127,
           0.003508772002533078,
           0.13237640261650085,
           0.1515151560306549,
           0.02647527866065502,
           0.001275917049497366,
           0.012121211737394333,
           0.027751196175813675,
           0.01116427406668663,
           0.0044657099060714245,
           0.014673045836389065
          ],
          [
           0.0345899723470211,
           0.2499028444290161,
           0.0007773027755320072,
           0.0003886513877660036,
           0.0007773027755320072,
           0.22114263474941254,
           0.0003886513877660036,
           0.0003886513877660036,
           0.0007773027755320072,
           0.3544500470161438,
           0.0003886513877660036,
           0.0015546055510640144,
           0.0058297705836594105,
           0.0003886513877660036,
           0.0034978624898940325,
           0.05985231325030327,
           0.0003886513877660036,
           0.0003886513877660036,
           0.01904391683638096,
           0.0003886513877660036,
           0.0003886513877660036,
           0.003109211102128029,
           0.003109211102128029,
           0.0003886513877660036,
           0.0003886513877660036,
           0.04741546884179115,
           0.0003886513877660036
          ],
          [
           0.055974166840314865,
           0.30247578024864197,
           0.0021528524812310934,
           0.0010764262406155467,
           0.009687836281955242,
           0.16146394610404968,
           0.003229278838261962,
           0.0021528524812310934,
           0.025834230706095695,
           0.16038751602172852,
           0.0010764262406155467,
           0.007534984033554792,
           0.015069968067109585,
           0.003229278838261962,
           0.06350915133953094,
           0.03982777148485184,
           0.0010764262406155467,
           0.0010764262406155467,
           0.024757804349064827,
           0.02260495163500309,
           0.009687836281955242,
           0.027987083420157433,
           0.0010764262406155467,
           0.003229278838261962,
           0.0010764262406155467,
           0.07965554296970367,
           0.0021528524812310934
          ],
          [
           0.23672883212566376,
           0.14921090006828308,
           0.0028694404754787683,
           0.007173601072281599,
           0.008608321659266949,
           0.05308464914560318,
           0.005738880950957537,
           0.0014347202377393842,
           0.0028694404754787683,
           0.14777618646621704,
           0.0014347202377393842,
           0.0014347202377393842,
           0.05738880857825279,
           0.0028694404754787683,
           0.0028694404754787683,
           0.060258250683546066,
           0.0014347202377393842,
           0.0014347202377393842,
           0.0014347202377393842,
           0.045911047607660294,
           0.10186513513326645,
           0.008608321659266949,
           0.0014347202377393842,
           0.005738880950957537,
           0.055954087525606155,
           0.04447632655501366,
           0.028694404289126396
          ],
          [
           0.2054009884595871,
           0.2193126082420349,
           0.0028641570825129747,
           0.011865793727338314,
           0.027925532311201096,
           0.030891980975866318,
           0.0013297871919348836,
           0.003171031130477786,
           0.0023527005687355995,
           0.019742226228117943,
           0.0024549919180572033,
           0.008899345062673092,
           0.11303191632032394,
           0.015241407789289951,
           0.1868862509727478,
           0.02782324142754078,
           0.001636661239899695,
           0.0007160392706282437,
           0.029869066551327705,
           0.041121114045381546,
           0.01074058935046196,
           0.014525367878377438,
           0.010945172049105167,
           0.000511456630192697,
           0.0029664484318345785,
           0.0024549919180572033,
           0.008081014268100262
          ],
          [
           0.06713928282260895,
           0.3590492010116577,
           0.002085070824250579,
           0.0012510425876826048,
           0.0012510425876826048,
           0.15596330165863037,
           0.00041701417649164796,
           0.0008340283529832959,
           0.01834862306714058,
           0.15221017599105835,
           0.0012510425876826048,
           0.0012510425876826048,
           0.05170975998044014,
           0.015012510120868683,
           0.002085070824250579,
           0.04628857225179672,
           0.0012510425876826048,
           0.00041701417649164796,
           0.013761468231678009,
           0.002085070824250579,
           0.002085070824250579,
           0.030859049409627914,
           0.0012510425876826048,
           0.0016680567059665918,
           0.0008340283529832959,
           0.06171809881925583,
           0.019182652235031128
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(247,251,255)"
          ],
          [
           0.125,
           "rgb(222,235,247)"
          ],
          [
           0.25,
           "rgb(198,219,239)"
          ],
          [
           0.375,
           "rgb(158,202,225)"
          ],
          [
           0.5,
           "rgb(107,174,214)"
          ],
          [
           0.625,
           "rgb(66,146,198)"
          ],
          [
           0.75,
           "rgb(33,113,181)"
          ],
          [
           0.875,
           "rgb(8,81,156)"
          ],
          [
           1,
           "rgb(8,48,107)"
          ]
         ],
         "showscale": false
        },
        "height": 700,
        "margin": {
         "b": 50,
         "l": 0,
         "r": 0,
         "t": 50
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now would write some plotly code to visualize the bigrams tensor\n",
    "x = px.imshow(p_matrix, x = list(chartoidx.keys()),\n",
    "                     y = list(chartoidx.keys()),\n",
    "                      color_continuous_scale='blues',\n",
    "                      width= 800,\n",
    "                      height = 700,\n",
    "                      \n",
    "                      )\n",
    "x.update_traces(texttemplate = \"%{y}%{x}<br>%{z}\")\n",
    "x.update_layout(margin=dict(l=0, r=0, t=50, b=50))\n",
    "x.update_coloraxes(showscale = False)\n",
    "x.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mor.\n",
      "axx.\n",
      "minaymoryles.\n",
      "kondlaisah.\n",
      "anchshizarie.\n",
      "odaren.\n",
      "iaddash.\n",
      "h.\n",
      "jhinatien.\n",
      "egushl.\n"
     ]
    }
   ],
   "source": [
    "# We could write a loop to genrate character given a starting word from the probability distribution of characters.\n",
    "generator = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(10):\n",
    "    ix = 0 # start \n",
    "    out = []\n",
    "    while True:\n",
    "        p = p_matrix[ix]\n",
    "        # p = bigram_tensor[ix].float()\n",
    "        # p = p/p.sum()\n",
    "        ix = torch.multinomial(p, generator=generator, num_samples=1, replacement=True).item()\n",
    "        out.append(idxtochar[ix])\n",
    "        if ix == 0:\n",
    "            # We have an end token. We would exit the loop\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. So we trained a bigram language model by litreally counting how much a pairing occurs and we trained it by normalizing the pairing and sampling from the probability distribution by giving it the starting character and sampling the next character from the probability distribution.\n",
    "2. So the elements of the array P are the parameters of our bigram language model.\n",
    "3. Now we would like to evaluate the quality of this model into a single number. We would evalute the training loss.\n",
    "4. So what we would do is that we would like to look at the probabilities that our trained model assigns to these bigrams.\n",
    "5. Now what the model is doing that it is summarizing the probabilities that it thinks are likely. So if everything was equallly likely then each and every bigram  would have a probability of roughly equal to 4%. So if it assigns a probability of more than 4% to any bigram that means that it has learned something from the statistics (count) that we have calculated.\n",
    "6. Basically if we have a very good model we would expect these probabilities to be near 1 for every bigram which shows that the model accurately predicts the next token given one token. So this would be a good model.\n",
    "7. So how can we summarize these probabilities which can measure the quality of the model in a single number.\n",
    "8. When we look at the litreature of maximum likelihood estimation we see that it contains something called as the likelihood which is the product of all the individual prbabilities and what it is telling us is the probabilities of the entire dataset assigned by the model.\n",
    "9. So as the product is a very small number because they all are probabilities we actually look at the `log-likelihood` of the probabilities.\n",
    "10. The log_prob is convinient because as the likelihood is the product of probabilities, the log_likelihood is the sum of the logs of individual probabilities.\\\n",
    "log(a*b*c) = log(a) + log(b) + log(c)\n",
    "11. So when all the probabilities are 1 the log likelihood will be zero. And as we move away from 1 the probabillites will go down to be negative i.e the log likelihood will be more and more negtive. But by common sense we need the loss to a high number so that when we minimize the loss it can get to zero. So we invert the log_likelihood by multiplying it  by -1.\n",
    "12. What some people also like to do is they like to make the nLL loss as an average rather than an absolute value. So they divide by the count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_likelihood = -559322.6875\n",
      "nLL = 559322.6875\n",
      "normlaized_nLL = 2.4515998363494873\n"
     ]
    }
   ],
   "source": [
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "for word in names:\n",
    "    word =  ['.'] + list(word) + ['.']\n",
    "    for char1, char2 in zip(word, word[1:]):\n",
    "        prob = p_matrix[chartoidx[char1]][chartoidx[char2]]\n",
    "        log_prob = torch.log(prob)\n",
    "        log_likelihood += log_prob\n",
    "        n+=1\n",
    "        # print(f\"{char1}{char2}: {prob.item():.4f} : {log_prob: .4f}\")\n",
    "\n",
    "print(f\"log_likelihood = {log_likelihood}\")\n",
    "print(f\"nLL = {-log_likelihood}\")\n",
    "print(f\"normlaized_nLL = {-log_likelihood/n}\")\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the probability of any word that we want by replacing the names of the dataset with our own name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".a: 0.1377 : -1.9827\n",
      "an: 0.1605 : -1.8294\n",
      "na: 0.1625 : -1.8171\n",
      "an: 0.1605 : -1.8294\n",
      "nt: 0.0242 : -3.7203\n",
      "t.: 0.0869 : -2.4431\n",
      "log_likelihood = -13.621914863586426\n",
      "nLL = 13.621914863586426\n",
      "normlaized_nLL = 2.2703192234039307\n"
     ]
    }
   ],
   "source": [
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "for word in ['anant']:\n",
    "    word =  ['.'] + list(word) + ['.']\n",
    "    for char1, char2 in zip(word, word[1:]):\n",
    "        prob = p_matrix[chartoidx[char1]][chartoidx[char2]]\n",
    "        log_prob = torch.log(prob)\n",
    "        log_likelihood += log_prob\n",
    "        n+=1\n",
    "        print(f\"{char1}{char2}: {prob.item():.4f} : {log_prob: .4f}\")\n",
    "\n",
    "print(f\"log_likelihood = {log_likelihood}\")\n",
    "print(f\"nLL = {-log_likelihood}\")\n",
    "print(f\"normlaized_nLL = {-log_likelihood/n}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.27 is a not a very good probability score of our name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we assign a very arbitrary string to the model in which the probability of that bigram is zero in our model. Then it will give out infinity loss which is not very desirable. In order to combat this we add some number to the zero counts to make them a little bit larger and to make the probability of random string very unlikely but not zero. `This is called as model smoothening.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".a: 0.1377 : -1.9827\n",
      "an: 0.1605 : -1.8294\n",
      "na: 0.1625 : -1.8171\n",
      "an: 0.1605 : -1.8294\n",
      "nt: 0.0242 : -3.7203\n",
      "tq: 0.0002 : -8.6252\n",
      "q.: 0.1066 : -2.2385\n",
      "log_likelihood = -22.04250717163086\n",
      "nLL = 22.04250717163086\n",
      "normlaized_nLL = 3.1489295959472656\n"
     ]
    }
   ],
   "source": [
    "# without the model smoothening we can see that the loss is infinity because one bigram has zero probability.\n",
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "for word in ['anantq']:\n",
    "    word =  ['.'] + list(word) + ['.']\n",
    "    for char1, char2 in zip(word, word[1:]):\n",
    "        prob = p_matrix[chartoidx[char1]][chartoidx[char2]]\n",
    "        log_prob = torch.log(prob)\n",
    "        log_likelihood += log_prob\n",
    "        n+=1\n",
    "        print(f\"{char1}{char2}: {prob.item():.4f} : {log_prob: .4f}\")\n",
    "\n",
    "print(f\"log_likelihood = {log_likelihood}\")\n",
    "print(f\"nLL = {-log_likelihood}\")\n",
    "print(f\"normlaized_nLL = {-log_likelihood/n}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above model asigned a very low probability to tq but not zero so the loss was high but not infinity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we would like to cast the problem of bigram model into a neural network\n",
    "So what the neural network would do is to predict the next character of the bigram sequence given the first character. We would also output a loss  number and based on this loss number we will optimize the Neural Network and reduce the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first thing that we would do is to make the training dataset of bigrams\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for word in names[:1]:\n",
    "    word =  ['.'] + list(word) + ['.']\n",
    "    for char1, char2 in zip(word, word[1:]):\n",
    "        ix1 = chartoidx[char1]\n",
    "        ix2 = chartoidx[char2]\n",
    "\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  5, 13, 13,  1]), tensor([ 5, 13, 13,  1,  0]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we would use one-hot encoding to represent each individual index of word in the vocabulary. The resulting tensor would be 27 charcers long\n",
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes = 27).float()\n",
    "yenc = F.one_hot(ys, num_classes = 27).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ]
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.imshow(xenc, color_continuous_scale=\"viridis\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will code our first neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0123,  1.4722, -2.1259,  0.9604,  1.2482,  0.2534,  2.8188, -0.3398,\n",
       "          1.7807,  1.4590, -0.1902, -0.6965,  1.7039,  0.7420,  0.9737,  0.3003,\n",
       "         -2.2396, -0.7125, -0.8790,  0.1066,  1.8598,  0.0558,  1.2815, -0.6318,\n",
       "         -0.7340,  2.0002, -0.3946],\n",
       "        [ 0.5259, -0.6117,  0.5482, -0.2568, -1.5437,  0.3795, -1.7705, -1.2085,\n",
       "          0.9477,  0.1029, -0.6808,  0.7951,  0.5766, -0.7378, -1.5264,  0.7117,\n",
       "          1.4056,  1.3924,  0.4346,  0.4979,  0.1130, -0.4185,  0.1791,  0.2348,\n",
       "          0.7351, -0.3884, -0.8240],\n",
       "        [-0.4116, -1.6739, -0.9180,  1.5021, -0.6285, -0.4425,  0.5689,  1.2803,\n",
       "         -0.5540, -0.1041,  1.4335, -0.5862, -0.2828,  0.5339, -0.9939, -1.6996,\n",
       "          1.8362, -0.3288,  0.7960, -0.3506,  0.7560, -0.9363, -0.0841, -1.6361,\n",
       "          1.0224,  0.0985,  1.1773],\n",
       "        [-0.4116, -1.6739, -0.9180,  1.5021, -0.6285, -0.4425,  0.5689,  1.2803,\n",
       "         -0.5540, -0.1041,  1.4335, -0.5862, -0.2828,  0.5339, -0.9939, -1.6996,\n",
       "          1.8362, -0.3288,  0.7960, -0.3506,  0.7560, -0.9363, -0.0841, -1.6361,\n",
       "          1.0224,  0.0985,  1.1773],\n",
       "        [ 0.0144,  0.5722,  0.8673,  0.6315, -1.2230, -0.7319, -0.2145,  0.3271,\n",
       "          1.9661, -0.2409, -0.7952,  0.2720, -1.1100,  0.9805,  0.4113,  1.2648,\n",
       "          1.4625,  1.1199,  0.9954, -1.2353,  0.7382, -0.6378, -0.0153,  0.5671,\n",
       "         -1.4601, -0.2478,  0.8828]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets define the weights of our neuron\n",
    "w = torch.randn((27,27), requires_grad=True, generator=generator)\n",
    "xenc@w   #(5,27) @ (27,27) = (5,27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0130, 0.0575, 0.0016, 0.0345, 0.0460, 0.0170, 0.2212, 0.0094, 0.0783,\n",
       "         0.0568, 0.0109, 0.0066, 0.0725, 0.0277, 0.0350, 0.0178, 0.0014, 0.0065,\n",
       "         0.0055, 0.0147, 0.0848, 0.0140, 0.0475, 0.0070, 0.0063, 0.0976, 0.0089],\n",
       "        [0.0463, 0.0148, 0.0474, 0.0212, 0.0058, 0.0400, 0.0047, 0.0082, 0.0706,\n",
       "         0.0303, 0.0139, 0.0606, 0.0487, 0.0131, 0.0059, 0.0558, 0.1116, 0.1101,\n",
       "         0.0423, 0.0450, 0.0306, 0.0180, 0.0327, 0.0346, 0.0571, 0.0186, 0.0120],\n",
       "        [0.0157, 0.0044, 0.0095, 0.1064, 0.0126, 0.0152, 0.0419, 0.0853, 0.0136,\n",
       "         0.0214, 0.0994, 0.0132, 0.0179, 0.0404, 0.0088, 0.0043, 0.1486, 0.0171,\n",
       "         0.0525, 0.0167, 0.0505, 0.0093, 0.0218, 0.0046, 0.0659, 0.0262, 0.0769],\n",
       "        [0.0157, 0.0044, 0.0095, 0.1064, 0.0126, 0.0152, 0.0419, 0.0853, 0.0136,\n",
       "         0.0214, 0.0994, 0.0132, 0.0179, 0.0404, 0.0088, 0.0043, 0.1486, 0.0171,\n",
       "         0.0525, 0.0167, 0.0505, 0.0093, 0.0218, 0.0046, 0.0659, 0.0262, 0.0769],\n",
       "        [0.0216, 0.0378, 0.0507, 0.0401, 0.0063, 0.0102, 0.0172, 0.0296, 0.1522,\n",
       "         0.0167, 0.0096, 0.0280, 0.0070, 0.0568, 0.0321, 0.0755, 0.0920, 0.0653,\n",
       "         0.0577, 0.0062, 0.0446, 0.0113, 0.0210, 0.0376, 0.0049, 0.0166, 0.0515]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we would want to convert the outputs of the matrix multiplication to be some sort of probabilities of the occurence of the next word\n",
    "# But the probabilities have a special structure. They are positive and sum to 1.\n",
    "# They cannot be counts because counts are integers and they are positive, so they are not a good type of output.\n",
    "# So we are going to interpret the output of the  neural net i.e. the 27 numbers as log counts or LOGITS basically.\n",
    "# To get the counts we are going to get the log counts and exponentiate them.\n",
    "# In exponentiation operation For negative numbers we get numbers less than 1(but not negative) and for postive numbers we get numbers greater than 1.\n",
    "# So the probabilities are just the counts normalized\n",
    "logits = (xenc@w)   # Log-counts\n",
    "counts = logits.exp()  # counts\n",
    "probs = counts/counts.sum(dim=1, keepdims = True)  # So the probabilities are just the counts normalized\n",
    "probs      # You get a 5,27 tensor of the probabilites of each character."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. All of the operation done above are differentiable operation. So we can backpropagate through the network.\\\n",
    "2. Now the question is to find the values of w for which the probabilities that come out are pretty good next characters. And the way that we find out pretty good is through the loss function\n",
    "3. The last two operation of exponentiation and normalization of the logits is called as the softmax. Softmax function exponentiates and normalizes the logits to produce probabilities.\n",
    "4. But right now the probabilities are very bad at predicting the next word. What we can do is that we can resample the w to see if we can get better probabilites by changing the seed of the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 27]) tensor(5., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# every row has a shape of 1,27 and has a sum of 1\n",
    "print(probs.shape, probs.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9469, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Forward Pass\n",
    "logits = (xenc@w)   # Log-counts\n",
    "counts = logits.exp()  # counts\n",
    "probs = counts/counts.sum(dim=1, keepdims = True)  # So the probabilities are just the counts normalized\n",
    "probs      # You get a 5,27 tensor of the probabilites of each character.\n",
    "\n",
    "\n",
    "# We are interested in the probabilities of the labels of the model.\n",
    "# So out of the probabilities outputted by the model we will take out the prbabilities at the index of the labels ys\n",
    "# Now we will evaluate the loss which will take the probability tensor and give the probabilities at the index of the labels.\n",
    "# We will also average the losses and take the log so that the loss is a positive number\n",
    "loss = -probs[torch.arange(5), ys].mean().log()\n",
    "print(loss)\n",
    "\n",
    "\n",
    "# Now we will do the backward pass\n",
    "# First reset the grdients to zeros\n",
    "w.grad = None\n",
    "\n",
    "# Doing the backward pass\n",
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 27])\n"
     ]
    }
   ],
   "source": [
    "# printing the gradient shape\n",
    "print(w.grad.shape)\n",
    "\n",
    "# updating the weights\n",
    "w.data += -0.1*w.grad\n",
    "# If we recalculate the forward pass loss should be lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first thing that we would do is to make the training dataset of bigrams\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for word in names[:1]:\n",
    "    word =  ['.'] + list(word) + ['.']\n",
    "    for char1, char2 in zip(word, word[1:]):\n",
    "        ix1 = chartoidx[char1]\n",
    "        ix2 = chartoidx[char2]\n",
    "\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes = 27).float()\n",
    "yenc = F.one_hot(ys, num_classes = 27).float()\n",
    "\n",
    "w = torch.randn((27,27), requires_grad=True, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 1.169492483139038\n",
      "Epoch: 10 | Loss: 1.1404589414596558\n",
      "Epoch: 20 | Loss: 1.113649606704712\n",
      "Epoch: 30 | Loss: 1.0892647504806519\n",
      "Epoch: 40 | Loss: 1.0673104524612427\n",
      "Epoch: 50 | Loss: 1.0476566553115845\n",
      "Epoch: 60 | Loss: 1.030092716217041\n",
      "Epoch: 70 | Loss: 1.014372706413269\n",
      "Epoch: 80 | Loss: 1.000246286392212\n",
      "Epoch: 90 | Loss: 0.9874756932258606\n",
      "Epoch: 100 | Loss: 0.9758449196815491\n",
      "Epoch: 110 | Loss: 0.9651618599891663\n",
      "Epoch: 120 | Loss: 0.955258846282959\n",
      "Epoch: 130 | Loss: 0.9459893703460693\n",
      "Epoch: 140 | Loss: 0.9372262954711914\n",
      "Epoch: 150 | Loss: 0.9288581609725952\n",
      "Epoch: 160 | Loss: 0.9207869172096252\n",
      "Epoch: 170 | Loss: 0.9129248261451721\n",
      "Epoch: 180 | Loss: 0.9051932692527771\n",
      "Epoch: 190 | Loss: 0.8975202441215515\n",
      "Epoch: 200 | Loss: 0.8898394703865051\n",
      "Epoch: 210 | Loss: 0.8820886611938477\n",
      "Epoch: 220 | Loss: 0.8742100596427917\n",
      "Epoch: 230 | Loss: 0.8661486506462097\n",
      "Epoch: 240 | Loss: 0.8578534126281738\n",
      "Epoch: 250 | Loss: 0.8492769598960876\n",
      "Epoch: 260 | Loss: 0.8403776288032532\n",
      "Epoch: 270 | Loss: 0.8311194777488708\n",
      "Epoch: 280 | Loss: 0.8214751482009888\n",
      "Epoch: 290 | Loss: 0.8114279508590698\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Lets rearrange everythig to work out of a loop\n",
    "for k in range(300):\n",
    "    logits = (xenc@w)   # Log-counts\n",
    "    counts = logits.exp()  # counts\n",
    "    probs = counts/counts.sum(dim=1, keepdims = True)  # So the probabilities are just the counts normalized\n",
    "    loss = -probs[torch.arange(5), ys].mean().log() + 0.01*(w**2).mean()   # Adding regularization to the loss.\n",
    "    w.grad = None\n",
    "    loss.backward()\n",
    "    w.data += -0.1*w.grad\n",
    "\n",
    "    if k%10 == 0:\n",
    "        print(f\"Epoch: {k} | Loss: {loss}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization restricts the growth of the weights. It is added as a loss to the loss parameter where what it does is that it forces the weights to be closer to zero by adding to the loss. So if the weights grow rapidly in the positive or the negative direction then what we do is we add the mean_quared weights to the loss which increases the loss. So the Neural Network does not like this increased loss and it forces the weights to decrease in accordance to the increased loss and thereby due to gradient descent and parameter update the values of weights get chopped down aggresively. This has a sort of smoothening effect on the weights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5863a01bb4350d9241febf9e57f76b3c44dc4260331656e165259b66bc149002"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
